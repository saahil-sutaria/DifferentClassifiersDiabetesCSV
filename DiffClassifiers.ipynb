{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnbc=GaussianNB()\n",
    "knnc=KNeighborsClassifier(n_neighbors=3)\n",
    "lrc=LogisticRegression(solver='liblinear')\n",
    "f=pd.read_csv('diabetes.csv')\n",
    "splitted_data=kf.split(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD  1\n",
      "Naive Bayes:  0.05194805194805195\n",
      "Logistic:  0.12987012987012986\n",
      "Knn:  0.0\n",
      "\n",
      "FOLD  2\n",
      "Naive Bayes:  0.0\n",
      "Logistic:  0.05194805194805195\n",
      "Knn:  0.012987012987012988\n",
      "\n",
      "FOLD  3\n",
      "Naive Bayes:  -0.05194805194805195\n",
      "Logistic:  0.05194805194805195\n",
      "Knn:  -0.07792207792207792\n",
      "\n",
      "FOLD  4\n",
      "Naive Bayes:  -0.03896103896103896\n",
      "Logistic:  0.0\n",
      "Knn:  -0.1038961038961039\n",
      "\n",
      "FOLD  5\n",
      "Naive Bayes:  -0.09090909090909091\n",
      "Logistic:  0.06493506493506493\n",
      "Knn:  -0.03896103896103896\n",
      "\n",
      "FOLD  6\n",
      "Naive Bayes:  -0.05194805194805195\n",
      "Logistic:  -0.012987012987012988\n",
      "Knn:  -0.03896103896103896\n",
      "\n",
      "FOLD  7\n",
      "Naive Bayes:  0.2077922077922078\n",
      "Logistic:  0.23376623376623376\n",
      "Knn:  0.12987012987012986\n",
      "\n",
      "FOLD  8\n",
      "Naive Bayes:  0.09090909090909091\n",
      "Logistic:  0.14285714285714285\n",
      "Knn:  0.09090909090909091\n",
      "\n",
      "FOLD  9\n",
      "Naive Bayes:  0.10526315789473684\n",
      "Logistic:  0.14473684210526316\n",
      "Knn:  0.14473684210526316\n",
      "\n",
      "FOLD  10\n",
      "Naive Bayes:  0.013157894736842105\n",
      "Logistic:  0.039473684210526314\n",
      "Knn:  0.0\n"
     ]
    }
   ],
   "source": [
    "nb=[]\n",
    "knn=[]\n",
    "lr=[]\n",
    "for train,test in splitted_data:\n",
    "    gnbc.fit(f.iloc[train[:],0:8],f.iloc[train[:],8])\n",
    "    knnc.fit(f.iloc[train[:],0:8],f.iloc[train[:],8])\n",
    "    lrc.fit(f.iloc[train[:],0:8],f.iloc[train[:],8])\n",
    "    tem=gnbc.predict(f.iloc[test[:],0:8])\n",
    "    actual=list(f.iloc[test[:],8])\n",
    "    err=actual-tem\n",
    "    nb.append(sum(err)/len(test))\n",
    "    tem=knnc.predict(f.iloc[test[:],0:8])\n",
    "    actual=f.iloc[test[:],8]\n",
    "    err=actual-tem\n",
    "    knn.append(sum(err)/len(test))\n",
    "    tem=lrc.predict(f.iloc[test[:],0:8])\n",
    "    actual=f.iloc[test[:],8]\n",
    "    err=actual-tem\n",
    "    lr.append(sum(err)/len(test))\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"\\nFOLD \",i+1)\n",
    "    print(\"Naive Bayes: \",nb[i])\n",
    "    print(\"Logistic: \",lr[i])\n",
    "    print(\"Knn: \",knn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T critical: 1.3830287383964925\n",
      "T value: 1.3830287383964925\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "#################   ANSWER 2  #################\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "nb=np.abs(nb)\n",
    "mean=np.mean(nb)\n",
    "std_dev=np.std(nb)\n",
    "t=np.sqrt(10)*(mean-0.2)/std_dev\n",
    "df=10-1\n",
    "t=stats.t.ppf(0.9,df)\n",
    "print(\"T critical:\",t)\n",
    "print(\"T value:\",t)\n",
    "if t>t:\n",
    "    print(\"No\")\n",
    "else:\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T value: 3.980571757324566\n",
      "T critical: -0.06447679010158362\n",
      "different errors values\n"
     ]
    }
   ],
   "source": [
    "################# ANSWER 3 #################\n",
    "\n",
    "t=np.sqrt(10)*mean/std_dev\n",
    "tc=stats.t.ppf(0.95/2,df)\n",
    "diff=nb-knn\n",
    "mean=np.mean(diff)\n",
    "std_dev=np.std(diff)\n",
    "print(\"T value:\",t)\n",
    "print(\"T critical:\",tc)\n",
    "if t>=tc and t<=-tc:\n",
    "    print(\"error is same\")\n",
    "else:\n",
    "    print(\"different errors values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same errors\n",
      "value of Estimators ratio: 2.0015640596710798\n",
      "value of f: 3.3541308285291986\n"
     ]
    }
   ],
   "source": [
    "################# ANSWER 4 #################\n",
    "et=np.array(np.transpose([knn,nb,lr]))\n",
    "nm=np.shape(et)[1]\n",
    "classifier_error_average=np.mean(et,axis=0)\n",
    "ew=np.sum(np.var(et,axis=0)/nm)\n",
    "eb=10*np.var(classifier_error_average)\n",
    "f=stats.f.ppf(0.95,dfn=nm-1,dfd=nm*(10-1))\n",
    "if eb/ew<f:\n",
    "    print(\"same errors\")\n",
    "else:\n",
    "    print(\"different errors\")\n",
    "print(\"value of Estimators ratio:\",eb/ew)\n",
    "print(\"value of f:\",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############  ANSWER 5  ###############\n",
    "class Naive:\n",
    "    def __init__(self):\n",
    "        self.mean=[]\n",
    "        self.variance=[]\n",
    "        self.prior=[]\n",
    "    def con_probability(self,x):\n",
    "        result=[]\n",
    "        for i in range(self.mean.shape[0]):\n",
    "            num=np.exp(-((x-self.mean[i])**2)/(2*self.variance[i]))\n",
    "            den=np.sqrt(2*np.pi*self.variance[i])\n",
    "            result.append((num/den).item())\n",
    "        return np.array(result)\n",
    "    def fit(self,x_train,y_train):\n",
    "        no_of_classes=np.unique(y_train).shape[0]\n",
    "        for i in range(no_of_classes):\n",
    "            rd=x_train[y_train==i]\n",
    "            self.prior.append(rd.shape[0]/x_train.shape[0])\n",
    "            self.mean.append(np.mean(rd))\n",
    "            self.variance.append(np.var(rd))\n",
    "        self.mean=np.array(self.mean)\n",
    "        self.variance=np.array(self.variance)\n",
    "        self.prior=np.array(self.prior)\n",
    "    def predict(self,x):\n",
    "        pre=[]\n",
    "        for x_data in x:\n",
    "            prob=self.con_probability(x_data)*self.prior\n",
    "            pre.append(np.argmax(prob))\n",
    "        return np.array(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Library model  Custom model\n",
      "0       0.311688      0.311688\n",
      "1       0.220779      0.220779\n",
      "2       0.246753      0.246753\n",
      "3       0.272727      0.272727\n",
      "4       0.246753      0.246753\n",
      "5       0.246753      0.246753\n",
      "6       0.233766      0.233766\n",
      "7       0.259740      0.259740\n",
      "8       0.197368      0.197368\n",
      "9       0.263158      0.263158\n"
     ]
    }
   ],
   "source": [
    "frame=pd.read_csv('diabetes.csv')\n",
    "splitted_data=kf.split(frame)\n",
    "x=frame.loc[:,[\"Glucose\"]].values\n",
    "y=frame.iloc[:,-1].values\n",
    "skerr=[]\n",
    "cnerr=[]\n",
    "kf=KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "for train,validation in kf.split(frame):\n",
    "    cm=Naive()\n",
    "    sm=GaussianNB()\n",
    "    cm.fit(x[train],y[train])\n",
    "    pre=cm.predict(x[validation])\n",
    "    error=np.sum(pre!=y[validation])/np.shape(y[validation])[0]\n",
    "    cnerr.append(error)\n",
    "    sm.fit(x[train],y[train])\n",
    "    pre=sm.predict(x[validation])\n",
    "    error=np.sum(pre!=y[validation])/np.shape(y[validation])[0]\n",
    "    skerr.append(error)\n",
    "res=pd.DataFrame({\"Library model\":skerr,\"Custom model\":cnerr})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
